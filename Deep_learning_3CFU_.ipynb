{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {

    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
   
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Comparative Study of Text Classification Using Transformer-Based Transfer Learning vs. LSTM-Based Deep Learning from Scratch\n"
      ],
      "metadata": {
        "id": "iKaqTVGZuB1Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìå Project Overview\n",
        "\n",
        "This project compares two deep learning methods for classifying IMDB movie reviews as either positive or negative.\n",
        "\n",
        "\n",
        "1. **Transformer-Based Transfer Learning**:\n",
        "   - Utilizes a pretrained DistilBERT model (a lighter variant of BERT) from the Hugging Face Transformers library.\n",
        "   - Leverages transfer learning by fine-tuning the model on a specific text classification dataset.\n",
        "\n",
        "2. **GRU-Based Model From Scratch**:\n",
        "\n",
        "  - Builds a GRU (Gated Recurrent Unit) model without using any pretrained embeddings.\n",
        "\n",
        "  - Trains all layers, including the embedding matrix, from scratch.\n",
        "\n",
        "**Objective**:\n",
        "\n",
        "Evaluate and compare the performance of both methods in terms of:\n",
        "\n",
        "- Training and validation loss\n",
        "\n",
        "- Accuracy\n",
        "\n",
        "- Generalization ability\n",
        "\n",
        "- Training time and resource usage\n",
        "\n",
        "**Motivation**:\n",
        "\n",
        "- GRU-based models are classical deep learning approaches for sequence modeling and still offer simpler alternatives when resources are limited.\n",
        "\n",
        "- Transformer-based models have achieved state-of-the-art performance.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "This project demonstrates the strengths and trade-offs of each approach in a practical text classification scenario.\n",
        "\n"
      ],
      "metadata": {
        "id": "3QiTUjjruSZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Va_ku3TJyI7L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transfer Learning Part**: Distil_Bert_For_Sequence_Classification"
      ],
      "metadata": {
        "id": "wLfzkr-kx2ac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "importing libraries  "
      ],
      "metadata": {
        "id": "xmwsrE9Uxr1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from datasets import load_dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "woa8A45yIVE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "hugging face login to access the dataset"
      ],
      "metadata": {
        "id": "fynHonuEyOl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login\n",
        "# api key: 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"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaG1636VHkk7",
        "outputId": "990803c6-d875-48a9-d668-ca157787ec88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `google colab` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `google colab`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets huggingface_hub fsspec\n",
        "#run this cell if getting error after running the next cell\n",
        "#fsspec: filesystem interface library required by datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yAeiTYKtH8B2",
        "outputId": "382ca4d9-20e1-4b77-8725-f172ee8bd0cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.33.1)\n",
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.33.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (2025.3.2)\n",
            "Collecting fsspec\n",
            "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.5)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.33.2-py3-none-any.whl (515 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m515.4/515.4 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec, huggingface_hub, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.33.1\n",
            "    Uninstalling huggingface-hub-0.33.1:\n",
            "      Successfully uninstalled huggingface-hub-0.33.1\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.6.0 fsspec-2025.3.0 huggingface_hub-0.33.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "datasets",
                  "fsspec"
                ]
              },
              "id": "7c6ee3eb50ae4a889399451eeaa299bc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading dataset"
      ],
      "metadata": {
        "id": "ROUFp_vozFw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = load_dataset(\"stanfordnlp/imdb\")\n",
        "# Load dataset\n",
        "dataset = load_dataset(\"imdb\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592,
          "referenced_widgets": [
            "b4b20b0905ab44f2b5c57a40133831fc",
            "c9c9d26bcd3d42078dea296349d7e45d",
            "cd20428f40b34871b0ce187c15328ad7",
            "1a4a35ca62a247dcacc3f6a973fe82eb",
            "31f17097eeff4af091b12583d7747969",
            "e64792499ffb4622b69eed91fa387b3a",
            "227c79dc8e7c4071862f4bba06f88c87",
            "aa4afda7267545d7b166e61187c651ef",
            "d691e9c6a32c40edaee4ee5786409f86",
            "cc201112524e4cc093cca317e5b1299f",
            "568fb600734a454c8db7ea304b912ae9",
            "6b13a7474f96448da35a8a5a930e7395",
            "9e74808886764ee5a690ca74911700ab",
            "85c9b8d5e99a4074beb80897bb0088ba",
            "0833d014e60b462ebe0f7dd0ce9f93f3",
            "3bb4dc4668e244a29d64adc35759ca65",
            "975f0a94a2034946a2b62df73f1beb4d",
            "990945762e0b45dd8d47efe187a9cb70",
            "1ae578ec347c493f804c3dccb7cbacd9",
            "29afa6f5e4784f568c87c9f954c76258",
            "7a4bff1888a145da99a8099bb7ff6e79",
            "3a854feb295a44f08f9b506cbf167c22",
            "eec5dca19ac748b2b6a7b3453dba17b6",
            "06d8daf78ac84591ae3351190e185ddf",
            "ebba48dc743e446b9090c697e7d08f21",
            "ad2985c5d7e542ca8cdd3936fdbe417c",
            "8ea14ed82ded4ab39558cec9fecbf3fd",
            "c44d23fb028c4d1a8723bf6286278dcb",
            "557ac84bc85a4f21a6c7ffbac8110240",
            "038b1068c56442b599ba7a9581a73b69",
            "af5382b5c0594010ab94006606f240ef",
            "5ac2578275754cd2bbae6602f8e0c6b3",
            "0a0dd06ec864451fb69d75cc7d4c097f",
            "16c6b243cce9460a8e45495b844a3593",
            "f330db0da5a2444ca5ca1436f795fb74",
            "d95e3bbefcdc49b1abbe2d1dc33c253d",
            "0e57fe1137774866a3381915ad2fc413",
            "92b89330a51049f08ffca6092290f4ab",
            "48731c1a84184361ac89f29af7299b99",
            "d97e6656dd6e4899a8d8e29db88a0fb8",
            "919c1e3f24cb4264bb9d63621ea44994",
            "bbdbccfebf46402f9b8348e907394008",
            "49dc43b0d34147eaa3936e6da1248cc2",
            "13944aec2d6e4e04b330ee3edfe23d90",
            "a2e0cffa7e1e4ec7b97da87501ddbb11",
            "9d8548362bae48fdbec4efeace95130c",
            "81361721b7264ab593b98ef90f702b04",
            "c76f9e13f4be44c9b4a61cc64309a5c3",
            "4a0208cc710540ac9cc40c1cafef81ae",
            "545d5c87b32f40b7a0111533508e3763",
            "9f7660b1929a49cc82f2b07394b1f8b7",
            "6c6dd8ee2cd44126a8364202ca39a0c4",
            "26ff1b20878f4fbfb1d23a3a301494b0",
            "19549efb027b4638b3f2363254e30171",
            "8a651758911343c98f28c32f59c94ca9",
            "200115d5c2934d299ffa330c37531e95",
            "4a564cb49f5946aeaf3f825603d876b0",
            "ab1c3b59cc6c4c90b82015438852db88",
            "494809b189b24dfd981b785e4a9eb5bb",
            "ff97dd4817084f15a103deb452225767",
            "e7aecb5c14d24bc4a3e262d8aff7e685",
            "a4dc3d7246854f1eba213be30b8b062d",
            "e0a46a67c08a47649123d50cba3054ce",
            "320a29eb03e24605834fe5c4da7853d8",
            "a532e95167144208aa276b46bc57bb9d",
            "1538945d9d52465faff5310677c43880",
            "e41d2012e53e449682bcb1e272f61c3e",
            "6b6ee24e2d5043a2a59639a7c70b32bc",
            "1bbd1a95833a46c99c5f12ba9736e2d9",
            "bd500bf3b31f4069a332d445dbf47d07",
            "9a995b60fd814f8dae7d8b1155edc43d",
            "4439e10597c64d308f42ed7e15bb593d",
            "78e9a93e32f443e9913e82bd721627b0",
            "eb9feb49766e446eabfaaa352b8f95eb",
            "d239ca6774ae4d02bfe2f96361c04556",
            "16eba8df580e4c6e81ef84fd35d56301",
            "32a86b030b79495593859d509ff16688",
            "f596a3e023034517a3a85e481fb3e727",
            "eda6755ccee14745abe4ed698cbe277d",
            "1c1480a22e434c7a86c1baa4012340c6",
            "4d8f3bd807d842c69347e474b618730c",
            "9a4fed285bfe4629a218634caebf415a",
            "33efd5eb31c34daf99ba410750095c22",
            "4e3a88ac08454a2c8bcc90b294fbb94d",
            "43e992fbb1a74fbd898ad92c9dc4e58d",
            "101749defb374435be446d02de088f33",
            "6615ff04b5e94aaf8d881a73aa9b8074",
            "6c0955c195d4421ca0ab689214b39357",
            "c459c3fdbd8a4f0892e63e9cffb49f62",
            "c9d109dae078498f8153b4882fa832b1",
            "5977e784cbfd4c8da753e197c8962694",
            "979b86076f774772b5257a258ad11e64",
            "9aa1dd99a95e408593178b7aecd17d2b",
            "476dcd9f1dae4f83b4ffe3602dd827b5",
            "8a56cf334f944f04901b3a7679402742",
            "ca28af8da0ce4595808c981b1df8162b",
            "26c4a3461bb5443f8949fae33262af6c",
            "6b7c4a04b3674f0f928e44a63464b7aa",
            "665f7df0a29c4eaf9ace5b43d029c640",
            "337637920a7548e2964a95008d1ebbd7",
            "1e55950fa03e4e468f5d2d909f082c63",
            "b85ac2da72b14801aeb5ebd8f3cc368b",
            "cfbba561e2ea441891cd77ac74c9fd6d",
            "3e040892ca254a39be140b5cf045f1d8",
            "280347de55cb47a598574f8675e4eddd",
            "fc84524527e5433bbf589e73e5619253",
            "2ea5662241a74f589f31e1c4bd8c98bf",
            "8a349f7c1bde479c961a0cb9c0e0c9e2",
            "fbf5988bb179427ca6c0379d70619b5b",
            "e23ede8f74b3462d81ae53bcc450e163",
            "3f3d0583eed4481a94c607c1659d7828",
            "02293b1b79564fd9a3316805a568c4b7",
            "e4ba721467b94560b4a87a13f33e2570",
            "82fd1ac006cc41a6a26fa41d2c6f5206",
            "162d4925a5264f50ab9c8bc8a192c641",
            "114f9ff364a04e9fa355b5aa7c4ec984",
            "455d6c265708469dbe28b90b02eeb4e2",
            "464fabf89c354a4ea883935a6a644b12",
            "21ce14a5484d42829c432f5caf914e01",
            "7cfabbe9a5514535a0e965757df82abd",
            "1d7373f5097b4879a8ffa5d7bbda8bb2",
            "66debeb080a14589971185f14447f6c5",
            "3af4c889d1db4090a8b23e24d98b45da",
            "466ae973bbf44a32a63281bf6569916d",
            "434fde952b9146fe9b9dc36120fdd376",
            "cbea5b6cd79442eb846707f56a512d1f",
            "5dd94b1103dc49b88e45608be81efadb",
            "057111f47dd6426ebca350e3b2cda6e6",
            "a56e299387034d469e1ed4545134d19e",
            "ac27d0bd544e42fc9fcc14587883cdd6",
            "a03c4aff303b45a5b00813478562f80d",
            "13646852ec4244599677976daab540af",
            "4f06ba881ddc4b419d287ba34504f34e",
            "0e5f55d8e6ea4bc09084205db87d8fe4",
            "6e51069845b14d41956557080134057a",
            "0e29930cc9e246d49b4a745b934ba5db",
            "129291fd2fac4497861b15422b253556",
            "5b13f213e3c94da9bce120a52b443093",
            "b2e45f4ff1974489bb0788c32810a782",
            "1b0896d718a449b1afc50998957eac43",
            "7d2b8b1b14a746749f91f12ded80f468",
            "bca69775a6a04454816cffa36bb60ba0",
            "963e564c20c5455d828bb5217dbce07a",
            "e8cea696f65546e4974f20f3b2fce8c1",
            "c8d152c4f90045c6a95189f8bebe91bf",
            "67a09865f82648408c88958b7a54a51e",
            "40cd82ddd84b4e39a3e170bd965c9639",
            "89a3caa97e13422eae3c637245ed8491",
            "0b6ec80d9fd6401faf22e70f65c6080c",
            "65ea4dedb08248058c8d90a1683a7543",
            "aea8ab6017eb4226b224cf65dd1bf683",
            "8ae27a2215b24c8eb6fbcd3418350076",
            "d8666e5f6d9a4b7a97da6c977109a01d",
            "26d852f001f14d10902df5bf40de3be0"
          ]
        },
        "id": "eDcISXuAHemH",
        "outputId": "37d4be41-8d18-4763-8ad2-2161445dcaa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4b20b0905ab44f2b5c57a40133831fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b13a7474f96448da35a8a5a930e7395"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eec5dca19ac748b2b6a7b3453dba17b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "unsupervised-00000-of-00001.parquet:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16c6b243cce9460a8e45495b844a3593"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2e0cffa7e1e4ec7b97da87501ddbb11"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "200115d5c2934d299ffa330c37531e95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e41d2012e53e449682bcb1e272f61c3e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f596a3e023034517a3a85e481fb3e727"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c459c3fdbd8a4f0892e63e9cffb49f62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "337637920a7548e2964a95008d1ebbd7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "unsupervised-00000-of-00001.parquet:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f3d0583eed4481a94c607c1659d7828"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66debeb080a14589971185f14447f6c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f06ba881ddc4b419d287ba34504f34e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8cea696f65546e4974f20f3b2fce8c1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "info about data set"
      ],
      "metadata": {
        "id": "uvBGYNVvzLM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjG_PkNJIgDR",
        "outputId": "bf7b4592-ea7e-4e22-8f52-980f0046cd84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 25000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 25000\n",
            "    })\n",
            "    unsupervised: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 50000\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = dataset['train'].shuffle(seed=42).select(range(5000))\n",
        "test_data = dataset['test'].shuffle(seed=42).select(range(1000))"
      ],
      "metadata": {
        "id": "yhbyiNHqIoQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fuDvo2ovz454"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Preprocess (for Transformer)\n",
        "\n",
        "\n",
        "#Load the DistilBERT tokenizer (pretrained on lowercase English)\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "#Define a function to tokenize each text example:\n",
        "#Convert text to input IDs and attention masks\n",
        "# Pad or truncate to a fixed length of 256 tokens\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
        "\n",
        "#Apply the tokenizer to the entire training and test datasets\n",
        "train_tokenized = train_data.map(tokenize_function, batched=True)\n",
        "test_tokenized = test_data.map(tokenize_function, batched=True)\n",
        "\n",
        "#Convert tokenized datasets to PyTorch format, keeping only the required columns\n",
        "train_tokenized.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "test_tokenized.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "82ffa6e1a88040eab5035ad60d7a7862",
            "a3176c44497f498faf5d4dd7558c1a82",
            "e1dda7b91a5c4ca289023ee6ed808822",
            "01f0d2db6fef420baa3246cffab7a1f2",
            "5333a3d1e0d9433db7e9e68415c00814",
            "773b5001128d4bc69ec4ff801308fe31",
            "038aa5c58617492eb5157fe9dc91bb8f",
            "7463572db1ea42f5a122247dfe601ab8",
            "cdb8067af0914e79a25b81e7cbf077f7",
            "49bab487374a4640afefa18188acd9d0",
            "af1a76b6b95e47d0b366da044ae6def1",
            "8244c0ca4a0e4c28b699431a62d9fc6e",
            "06236d9c564242e2841cd36776ea61fa",
            "85bd4219881242cd9ae2a4c7166cecfa",
            "50a1c1afbfcb4b3e981bb17bf52d5a05",
            "1a056d1875f4423890d208cd0eb3c651",
            "8a9e259969a2432da74a5bf4c2f4780d",
            "a2deda103d6c43118753fc971cccf350",
            "9376ffb8ce7c45e4b9c5f1ee89518555",
            "c568817530d64cf3b3ff4265215ebb07",
            "9c00b545ada24cdc805b2b372aa48e3c",
            "5c37463abac2408584d8b4e87bfefc8c",
            "78dcd9ff70854cfb8efc1ade565f954b",
            "e921ab3ef50c4228985b9b4d61404766",
            "5c7563dab744415694c1ccc08ba83dee",
            "fdd78adc3869488f8c765cf8cb56a3c7",
            "bd205ad184e34dd59ab0209484b0fd0f",
            "ef67a2db4aab4c6196bb59189a1fd6b2",
            "64598a151c6749acbccafe80bc9171f8",
            "66ada29a683d419ea1d57cd6e92ab952",
            "4a25ba04d84b491bb5707efd69a1cdd4",
            "ed464d9e55714e188ac002e162d67570",
            "d9a4acdd3f1c4f85917e96275eb019e7",
            "6939e09e639e4400b16fb07a43d21e6e",
            "5ba2fb60df9a4b84a5d26ff90eb0b4ee",
            "4a57763498614fa587dc71a2518b483d",
            "b5c64aeab81c42bab05005a7b6fffdc5",
            "9757243a6b74485cb2e09e8211e8d615",
            "bb173166d0a542b4b73d86d1ec0883b5",
            "cbf0fe6ebbe7474bbdf6a4829a102064",
            "7a9044cb270740359349267621ab0144",
            "a1667d70012c481391f43fb3e76c1acb",
            "27a7e4e8765a48fd9b34f6c224216e17",
            "5fda77a050f7405fa93ec30bfb0ec3a3",
            "ab9b27b084be480dbd71d1f09bd963c0",
            "f4d96682197746fea271845e237e93ca",
            "eb52c8b5200d4a9285dd3e6b8137fbde",
            "1260788dcf0e44d0ad93f38fbe112fb6",
            "658c6fc68c4c4b97a22d52b737ee92d2",
            "7e30b850c69040cf9c37c2ef4d910175",
            "5b7395ba92d245089efe988ec06a149a",
            "b8616d8b38524fc3b6dfda57492cc77d",
            "d24c0963ff36439b8f08c9bce2f50d99",
            "e433b7b9dbfd4e3f998ce365efdcd11a",
            "d7b3130a3d254b6cb1278014505247cf",
            "d6784bd308544296aa18728280727bcb",
            "eac38be6ec9940ee90d99a5320cf60e8",
            "6040e46f52d04e3dbb91c753b2261426",
            "5cb7703d58684e48b9ddd572c487d984",
            "cac04f6bfb904635b69eba19ea0c99f5",
            "ee3a368cd32040b9ba56baa93b5b004d",
            "fc0877f4c9c444d589cc0aa5c096510b",
            "8f61493472634da8b1ba2a3c389394bf",
            "6c7be1f7097b42c0aebe990c6f19ba77",
            "2e7f53c76e0b4b00b1e1d7554374a900",
            "46a8500b19874219abf3e58f41e531fe"
          ]
        },
        "id": "ycQfe9mPJsma",
        "outputId": "60a056b3-c60f-4b71-dde7-8b5a8de64754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82ffa6e1a88040eab5035ad60d7a7862"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8244c0ca4a0e4c28b699431a62d9fc6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78dcd9ff70854cfb8efc1ade565f954b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6939e09e639e4400b16fb07a43d21e6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab9b27b084be480dbd71d1f09bd963c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6784bd308544296aa18728280727bcb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Transformer Model\n",
        "model_transformer = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
        "#optimizer\n",
        "optimizer = torch.optim.AdamW(model_transformer.parameters(), lr=5e-5)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_transformer.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712,
          "referenced_widgets": [
            "848d03619d794ee4bb822c722e3afdf5",
            "d8343aab0f8a471ab3860ca67f24cc93",
            "2e0ff5c8a6294c84aff2de04169a84de",
            "1180c4ac4d144a25aaec9b0287d3084d",
            "b001d848ac12457895903abdeae3c0ea",
            "8ebcf9631a8f46198714440a57445815",
            "2bde2e90d7024cc4bc4419fa28881a21",
            "c41b5b64d2c845f3bb0afedf2eab6210",
            "28dc1ba42506493384fe48cc3e18aa1b",
            "f05b79e7782b4796815f88102eaa6121",
            "be0c246d9ca541f781dde38af077e3e7"
          ]
        },
        "id": "t-2l-FAzJ4OP",
        "outputId": "04eabfaa-5678-4d4f-fc37-a6f0f63ed97d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "848d03619d794ee4bb822c722e3afdf5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): DistilBertSdpaAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#training function\n",
        "#Updating (fine-tunes) all model weights, starting from the pretrained DistilBERT weights.\n",
        "def train_transformer():\n",
        "    model_transformer.train()\n",
        "    for epoch in range(6):\n",
        "        epoch_losses = []\n",
        "        for batch in DataLoader(train_tokenized, batch_size=8, shuffle=True):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            batch[\"labels\"] = batch.pop(\"label\")\n",
        "            outputs = model_transformer(**batch)\n",
        "            loss = outputs.loss\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            epoch_losses.append(loss.item())\n",
        "\n",
        "        avg_loss = sum(epoch_losses) / len(epoch_losses)\n",
        "        print(f\"Epoch {epoch+1}, Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "train_transformer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imAzxvQIJ-or",
        "outputId": "194139b6-80e5-4933-96d1-fdfdec5bc915"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Average Loss: 0.3914\n",
            "Epoch 2, Average Loss: 0.1988\n",
            "Epoch 3, Average Loss: 0.0964\n",
            "Epoch 4, Average Loss: 0.0508\n",
            "Epoch 5, Average Loss: 0.0426\n",
            "Epoch 6, Average Loss: 0.0344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation of transfer model\n",
        "\n",
        "def evaluate_transformer():\n",
        "    model_transformer.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in DataLoader(test_tokenized, batch_size=8):#predicting on test tokenized data\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            batch[\"labels\"] = batch.pop(\"label\")  #Rename 'label' to 'labels'\n",
        "            outputs = model_transformer(**batch)\n",
        "            preds = torch.argmax(outputs.logits, dim=-1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(batch['labels'].cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
        "\n",
        "    print(\"Accuracy:\", acc)\n",
        "    print(\"F1 Score:\", f1)\n",
        "\n",
        "evaluate_transformer()\n"
      ],
      "metadata": {
        "id": "e44zuReMKXHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54e54902-6ff1-45c6-df40-4d97f2d823d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.863\n",
            "F1 Score: 0.8625405147347781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Total parameters that are fine-tuned\n",
        "\n",
        "total_params = sum(p.numel() for p in model_transformer.parameters() if p.requires_grad)\n",
        "print(f\"Total trainable parameters: {total_params}\")\n"
      ],
      "metadata": {
        "id": "1Fwh74ciDSpE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aee87b0a-6d63-47f2-c920-d81ef44001e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total trainable parameters: 66955010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5rP8bjZq16wS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GRU Model from scratch**\n",
        "GRU = Gated Recurrent Unit\n",
        "It's type of RNN designed to process sequential data (like text, time series, etc.).\n",
        "\n",
        "\n",
        "Core idea:\n",
        "Classic RNNs suffer from vanishing gradients, which means they struggle to learn long-term dependencies (e.g., words far apart in a sentence).\n",
        "GRUs solve this by using gates that control what information gets kept or forgotten."
      ],
      "metadata": {
        "id": "WFJK6IsuUx9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#libraries\n",
        "import pandas as pd\n",
        "import json\n",
        "import string\n",
        "import re\n",
        "import spacy\n",
        "import requests\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import difflib\n",
        "import random\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout, GRU\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from typing import Counter\n"
      ],
      "metadata": {
        "id": "WxSM6ANJUxZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    tf.random.set_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)"
      ],
      "metadata": {
        "id": "imihNrulVAz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tTw-Ku9H38_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Download GloVe embeddings from Stanford, unzip, and load them into a dictionary mapping words to vectors\n",
        "#will use this embedding mechanism after tokenization to represent the words in the fixed sized vectors\n",
        "# that will be used to train the model\n",
        "\n",
        "\n",
        "# Download glove dataset and unzip\n",
        "url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "\n",
        "response = requests.get(url)\n",
        "print(\"Downloaded GloVe zip\")\n",
        "\n",
        "zip_file = zipfile.ZipFile(BytesIO(response.content))\n",
        "glove_file = zip_file.open('glove.6B.100d.txt')\n",
        "\n",
        "# Parse GloVe vectors into dict: word -> vector\n",
        "glove = {}\n",
        "for line in glove_file:\n",
        "    parts = line.decode('utf-8').strip().split()\n",
        "    word = parts[0]\n",
        "    vec = np.array(parts[1:], dtype=np.float32)\n",
        "    glove[word] = vec\n",
        "\n",
        "print(f\"Loaded {len(glove)} GloVe word vectors\")\n"
      ],
      "metadata": {
        "id": "buhK5WjocqPa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1a6e2dc-9998-426c-c1f2-066702c58b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded GloVe zip\n",
            "Loaded 400000 GloVe word vectors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#collecting token from tweets of training data to build the vocabulary\n",
        "# just dividing words, not using subword technique\n",
        "\n",
        "def tokenize(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "# Gather all tokens from tweets\n",
        "all_tokens = []\n",
        "for review in train_data[\"text\"]:\n",
        "    all_tokens.extend(tokenize(review))\n",
        "\n",
        "token_counts = Counter(all_tokens)\n",
        "vocab = list(token_counts.keys()) # all the unique tokens\n",
        "print(f\"Vocabulary size: {len(vocab)}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jIxYS5fHXssu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9683e033-0e50-454a-a937-74e3dacd703a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 92230\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#making list for tokens that are present in glove and not\n",
        "in_glove_token=[tok for tok in vocab if tok in glove ]\n",
        "in_oov_token=[tok for tok in vocab if tok not in glove]\n",
        "\n",
        "#create a map, 1 for those oov token from validation and testing data set\n",
        "word2idx = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
        "idx = 2\n",
        "\n",
        "# Add in-glove tokens\n",
        "for tok in in_glove_token:\n",
        "    word2idx[tok] = idx\n",
        "    idx += 1\n",
        "\n",
        "print(\"Words found in Glove\",idx)\n",
        "#Add oov tokens\n",
        "for tok in in_oov_token:\n",
        "    word2idx[tok] = idx\n",
        "    idx += 1\n",
        "print(\"Overall\",idx)"
      ],
      "metadata": {
        "id": "9aY6Q3wPYtzN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8aa381d-7949-4c46-ccc4-ff80cdbfdd88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words found in Glove 32162\n",
            "Overall 92232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating vector/Embedding\n",
        "emb=100\n",
        "embedding_matrix=np.zeros((len(word2idx),emb))\n",
        "count1=0\n",
        "count=0\n",
        "# assignment of numercial sequence to each words\n",
        "# if have found the words in glove, assign embedding from there\n",
        "# otherwise randomly\n",
        "for tok in all_tokens:\n",
        "    if tok in glove:\n",
        "        count+=1\n",
        "        embedding_matrix[word2idx[tok]] = glove[tok]\n",
        "    else:\n",
        "        count1+=1\n",
        "        embedding_matrix[word2idx[tok]] = np.random.normal(scale=0.6, size=(emb,))\n",
        "\n",
        "\n",
        "# Now Embedding_matrix is the our complete vocabulary"
      ],
      "metadata": {
        "id": "DG536xVoZEoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating X_train and Y_train\n",
        "# and preparing data for the model\n",
        "# Function to convert words to token IDs\n",
        "def text_to_sequence(text, word2idx):\n",
        "    return [word2idx.get(word, word2idx[\"<UNK>\"]) for word in text.lower().split()]\n",
        "\n",
        "# Convert all reviews to sequences of IDs\n",
        "X_train = [text_to_sequence(tweet, word2idx) for tweet in train_data[\"text\"]]\n",
        "X_test= [text_to_sequence(tweet, word2idx) for tweet in test_data[\"text\"]]\n",
        "\n",
        "\n",
        "\n",
        "# Pad sequences to the same length\n",
        "max_len = max(len(seq) for seq in X_train)  # or set a fixed length like 50\n",
        "\n",
        "X_train_padded = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
        "# Convert labels to numpy array\n",
        "y_train = np.array(train_data[\"label\"])\n",
        "\n",
        "# padding testing data\n",
        "X_test_padded = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
        "# Convert labels to numpy array\n",
        "y_test = np.array(test_data[\"label\"])\n",
        "\n",
        "\n",
        "# Final shapes\n",
        "print(\"X_train shape:\", X_train_padded.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "\n",
        "\n",
        "# Final shapes\n",
        "print(\"X_test shape:\", X_test_padded.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Tl3hr83CZTEN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1675696f-fada-49b7-cb15-c17693ddbaaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (5000, 1601)\n",
            "y_train shape: (5000,)\n",
            "X_test shape: (1000, 1601)\n",
            "y_test shape: (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#defining Embedding layer and freeze the embedding layer\n",
        "# around 30 percent was taken from glove, remaining was initialized randomly\n",
        "vocab_size = len(word2idx)\n",
        "embedding_dim = embedding_matrix.shape[1]\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    input_dim=vocab_size,\n",
        "    output_dim=embedding_dim,\n",
        "    weights=[embedding_matrix],\n",
        "    input_length=max_len,\n",
        "     mask_zero=True,\n",
        "     trainable=False\n",
        "\n",
        ")\n"
      ],
      "metadata": {
        "id": "roPsZ3sfZrGO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0317a55b-ed66-404b-a430-755f5a609527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#defining model\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, GRU, Dropout, Dense, Add\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "input_seq = Input(shape=(max_len,))\n",
        "\n",
        "# Embedding layer\n",
        "x = embedding_layer(input_seq)  #which is defined in previous cell\n",
        "\n",
        "# First Bidirectional GRU + Dropout, Trainable\n",
        "gru1 = Bidirectional(GRU(64, return_sequences=True))(x)\n",
        "drop1 = Dropout(0.3)(gru1)\n",
        "\n",
        "residual_1 = drop1  # We'll add residual on next step\n",
        "\n",
        "# Second Bidirectional GRU + Dropout\n",
        "gru2 = Bidirectional(GRU(64, return_sequences=True))(drop1)\n",
        "drop2 = Dropout(0.3)(gru2)\n",
        "\n",
        "# Add residual connection from previous GRU output to current GRU output\n",
        "residual_2 = Add()([drop2, residual_1])  # element-wise add\n",
        "\n",
        "# Third Bidirectional GRU + Dropout\n",
        "gru3 = Bidirectional(GRU(64, return_sequences=True))(residual_2)\n",
        "drop3 = Dropout(0.3)(gru3)\n",
        "\n",
        "# Add residual connection from previous GRU output to current GRU output\n",
        "residual_3 = Add()([drop3, residual_2])  # element-wise add\n",
        "\n",
        "# Third Bidirectional GRU (no return sequences)\n",
        "gru4 = Bidirectional(GRU(64))(residual_3)\n",
        "drop4 = Dropout(0.3)(gru4)\n",
        "\n",
        "# Dense layers\n",
        "dense1 = Dense(64, activation='relu')(drop4)\n",
        "drop5 = Dropout(0.3)(dense1)\n",
        "\n",
        "output = Dense(1, activation='sigmoid')(drop5)\n",
        "\n",
        "model = Model(inputs=input_seq, outputs=output)\n",
        "\n",
        "\n",
        "#Compiling and builidng\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.build(input_shape=(None, max_len))  # max_len is the length of padded sequences\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "NTsrCIGiZ22Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 908
        },
        "outputId": "1787f3a5-670b-4edb-a59e-8d1737381215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ input_layer         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1601\u001b[0m)      ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ -                 ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mInputLayer\u001b[0m)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ embedding           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1601\u001b[0m, \u001b[38;5;34m100\u001b[0m) ‚îÇ  \u001b[38;5;34m9,223,200\u001b[0m ‚îÇ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ not_equal           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1601\u001b[0m)      ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mNotEqual\u001b[0m)          ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ bidirectional       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1601\u001b[0m, \u001b[38;5;34m128\u001b[0m) ‚îÇ     \u001b[38;5;34m63,744\u001b[0m ‚îÇ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mBidirectional\u001b[0m)     ‚îÇ                   ‚îÇ            ‚îÇ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout (\u001b[38;5;33mDropout\u001b[0m)   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1601\u001b[0m, \u001b[38;5;34m128\u001b[0m) ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ bidirectional[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ bidirectional_1     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1601\u001b[0m, \u001b[38;5;34m128\u001b[0m) ‚îÇ     \u001b[38;5;34m74,496\u001b[0m ‚îÇ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mBidirectional\u001b[0m)     ‚îÇ                   ‚îÇ            ‚îÇ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1601\u001b[0m, \u001b[38;5;34m128\u001b[0m) ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ bidirectional_1[\u001b[38;5;34m‚Ä¶\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ add (\u001b[38;5;33mAdd\u001b[0m)           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1601\u001b[0m, \u001b[38;5;34m128\u001b[0m) ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  ‚îÇ\n",
              "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ logical_or          ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1601\u001b[0m)      ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mLogicalOr\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ bidirectional_2     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1601\u001b[0m, \u001b[38;5;34m128\u001b[0m) ‚îÇ     \u001b[38;5;34m74,496\u001b[0m ‚îÇ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mBidirectional\u001b[0m)     ‚îÇ                   ‚îÇ            ‚îÇ logical_or[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1601\u001b[0m, \u001b[38;5;34m128\u001b[0m) ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ bidirectional_2[\u001b[38;5;34m‚Ä¶\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ add_1 (\u001b[38;5;33mAdd\u001b[0m)         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1601\u001b[0m, \u001b[38;5;34m128\u001b[0m) ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  ‚îÇ\n",
              "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ logical_or_1        ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1601\u001b[0m)      ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ logical_or[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mLogicalOr\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ logical_or[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ bidirectional_3     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       ‚îÇ     \u001b[38;5;34m74,496\u001b[0m ‚îÇ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mBidirectional\u001b[0m)     ‚îÇ                   ‚îÇ            ‚îÇ logical_or_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m‚Ä¶\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ bidirectional_3[\u001b[38;5;34m‚Ä¶\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        ‚îÇ      \u001b[38;5;34m8,256\u001b[0m ‚îÇ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_1 (\u001b[38;5;33mDense\u001b[0m)     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         ‚îÇ         \u001b[38;5;34m65\u001b[0m ‚îÇ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)        </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape      </span>‚îÉ<span style=\"font-weight: bold\">    Param # </span>‚îÉ<span style=\"font-weight: bold\"> Connected to      </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ input_layer         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1601</span>)      ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ -                 ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ embedding           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1601</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) ‚îÇ  <span style=\"color: #00af00; text-decoration-color: #00af00\">9,223,200</span> ‚îÇ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ not_equal           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1601</span>)      ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ bidirectional       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1601</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">63,744</span> ‚îÇ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     ‚îÇ                   ‚îÇ            ‚îÇ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1601</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ bidirectional_1     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1601</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">74,496</span> ‚îÇ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     ‚îÇ                   ‚îÇ            ‚îÇ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1601</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">‚Ä¶</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1601</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  ‚îÇ\n",
              "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ logical_or          ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1601</span>)      ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LogicalOr</span>)         ‚îÇ                   ‚îÇ            ‚îÇ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ bidirectional_2     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1601</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">74,496</span> ‚îÇ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     ‚îÇ                   ‚îÇ            ‚îÇ logical_or[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1601</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">‚Ä¶</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1601</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  ‚îÇ\n",
              "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ logical_or_1        ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1601</span>)      ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ logical_or[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LogicalOr</span>)         ‚îÇ                   ‚îÇ            ‚îÇ logical_or[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ bidirectional_3     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">74,496</span> ‚îÇ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     ‚îÇ                   ‚îÇ            ‚îÇ logical_or_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">‚Ä¶</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ bidirectional_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">‚Ä¶</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        ‚îÇ      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> ‚îÇ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> ‚îÇ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,518,753\u001b[0m (36.31 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,518,753</span> (36.31 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m295,553\u001b[0m (1.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">295,553</span> (1.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,223,200\u001b[0m (35.18 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,223,200</span> (35.18 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#have tested with multiple combination and final model have been trained on 20 epochs with learning rate=1e-4\n",
        "SEEDS = [42]\n",
        "results = []\n",
        "\n",
        "for seed in SEEDS:\n",
        "    print(f\"\\n\\nRunning experiments with seed: {seed}\")\n",
        "    set_seed(seed)\n",
        "\n",
        "    # Train Model 1\n",
        "\n",
        "    model.fit(X_train_padded, y_train, epochs=20, batch_size=16, validation_split=0.2 )\n",
        "\n"
      ],
      "metadata": {
        "id": "tP71hZqpacp_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "021afe98-1b6e-494f-ff51-280778824fb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Running experiments with seed: 42\n",
            "Epoch 1/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 152ms/step - accuracy: 0.5148 - loss: 0.7058 - val_accuracy: 0.5390 - val_loss: 0.6851\n",
            "Epoch 2/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 140ms/step - accuracy: 0.5304 - loss: 0.6907 - val_accuracy: 0.5850 - val_loss: 0.6743\n",
            "Epoch 3/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 146ms/step - accuracy: 0.5744 - loss: 0.6767 - val_accuracy: 0.6090 - val_loss: 0.6579\n",
            "Epoch 4/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 147ms/step - accuracy: 0.6075 - loss: 0.6608 - val_accuracy: 0.6310 - val_loss: 0.6354\n",
            "Epoch 5/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 144ms/step - accuracy: 0.6309 - loss: 0.6384 - val_accuracy: 0.6540 - val_loss: 0.6131\n",
            "Epoch 6/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 150ms/step - accuracy: 0.6703 - loss: 0.6118 - val_accuracy: 0.6680 - val_loss: 0.5955\n",
            "Epoch 7/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 145ms/step - accuracy: 0.6809 - loss: 0.6075 - val_accuracy: 0.6940 - val_loss: 0.5816\n",
            "Epoch 8/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 147ms/step - accuracy: 0.6950 - loss: 0.5799 - val_accuracy: 0.7100 - val_loss: 0.5688\n",
            "Epoch 9/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 139ms/step - accuracy: 0.7087 - loss: 0.5659 - val_accuracy: 0.7050 - val_loss: 0.5570\n",
            "Epoch 10/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 146ms/step - accuracy: 0.7246 - loss: 0.5476 - val_accuracy: 0.7130 - val_loss: 0.5447\n",
            "Epoch 11/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 140ms/step - accuracy: 0.7451 - loss: 0.5164 - val_accuracy: 0.7180 - val_loss: 0.5250\n",
            "Epoch 12/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 147ms/step - accuracy: 0.7603 - loss: 0.4922 - val_accuracy: 0.7230 - val_loss: 0.5561\n",
            "Epoch 13/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 140ms/step - accuracy: 0.7716 - loss: 0.4827 - val_accuracy: 0.7440 - val_loss: 0.5111\n",
            "Epoch 14/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 147ms/step - accuracy: 0.7862 - loss: 0.4606 - val_accuracy: 0.7510 - val_loss: 0.5027\n",
            "Epoch 15/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 147ms/step - accuracy: 0.7900 - loss: 0.4459 - val_accuracy: 0.7610 - val_loss: 0.5040\n",
            "Epoch 16/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 146ms/step - accuracy: 0.8126 - loss: 0.4210 - val_accuracy: 0.7740 - val_loss: 0.4889\n",
            "Epoch 17/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 140ms/step - accuracy: 0.8133 - loss: 0.4098 - val_accuracy: 0.7820 - val_loss: 0.4898\n",
            "Epoch 18/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 147ms/step - accuracy: 0.8239 - loss: 0.4049 - val_accuracy: 0.7880 - val_loss: 0.4738\n",
            "Epoch 19/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 140ms/step - accuracy: 0.8313 - loss: 0.3897 - val_accuracy: 0.7960 - val_loss: 0.4786\n",
            "Epoch 20/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 147ms/step - accuracy: 0.8449 - loss: 0.3724 - val_accuracy: 0.7880 - val_loss: 0.4884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding F1 score\n",
        "\n",
        "y_test_pred_model1 = (model.predict(X_test_padded) > 0.5).astype(int)\n",
        "f1_model1 = f1_score(y_test, y_test_pred_model1, average='macro')\n",
        "print(f\"Model 1 Macro F1: {f1_model1:.4f}\")\n",
        "\n",
        "    # Save results\n",
        "results.append({\n",
        "        \"seed\": seed,\n",
        "\n",
        "        \"model1_f1\": f1_model1\n",
        "    })\n"
      ],
      "metadata": {
        "id": "7LTCYsTSpZsh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e8ce7e2-c4eb-45aa-8acf-6401dc9a9333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step\n",
            "Model 1 Macro F1: 0.7758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary of Findings**:\n",
        "\n",
        "I trained a GRU-based model for sentiment classification on the IMDB dataset using frozen pre-trained GloVe embeddings(half of them are initailized randomly). This model has a total of approximately 9.5 million parameters, but most of them (~9.2 million) are non-trainable because the embedding layer is frozen. Only around 295,000 parameters are trainable in the rest of the model.\n",
        "\n",
        "The GRU model achieved a macro F1 score of about 0.77, which is decent given the smaller number of trainable parameters.\n",
        "\n",
        "In comparison, the Transformer-based model (DistilBERT) I used for transfer learning contains many more trainable parameters and achieved a higher macro F1 score of around 0.88.\n",
        "\n",
        "This suggests that while the GRU model is more lightweight and computationally efficient, the Transformer‚Äôs larger capacity and ability to fine-tune pre-trained weights provide better performance on this task.\n",
        "\n",
        "Freezing the embeddings in the GRU model likely limited its ability to fully adapt to the dataset, so allowing embedding fine-tuning might improve results at the cost of increased training time.\n",
        "\n",
        "**In conclusion**, for resource-constrained scenarios, GRU models with frozen embeddings are a good choice, but if accuracy is the priority and resources allow, fine-tuned Transformer models outperform them.\n"
      ],
      "metadata": {
        "id": "ZyPYkJsBBLJM"
      }
    }
  ]
}
